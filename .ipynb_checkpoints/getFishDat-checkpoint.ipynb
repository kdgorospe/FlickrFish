{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flickrapi in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (2.4.0)\n",
      "Requirement already satisfied: requests>=2.2.1 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from flickrapi) (2.21.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from flickrapi) (1.12.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.3.1 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from flickrapi) (0.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.0 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from flickrapi) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from requests>=2.2.1->flickrapi) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from requests>=2.2.1->flickrapi) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from requests>=2.2.1->flickrapi) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from requests>=2.2.1->flickrapi) (2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.4.0->flickrapi) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install flickrapi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flickrapi import FlickrAPI\n",
    "import pandas as pd\n",
    "import sys\n",
    "key='4d860f720718fdce373fe644da0d61b4'\n",
    "secret='813a60f10dffcbe6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(image_tag, MAX_COUNT):\n",
    "    \n",
    "\n",
    "    flickr = FlickrAPI(key, secret)\n",
    "    photos = flickr.walk(text=image_tag,\n",
    "                            tag_mode='all',\n",
    "                            tags=image_tag,\n",
    "                            extras='url_o, date_upload, date_taken, geo',\n",
    "                            per_page=50,\n",
    "                            sort='relevance',\n",
    "                            geocontext=2 #1 = return indoor photos; 2 = outdoor photos\n",
    "                        ) \n",
    "    count=0\n",
    "    urls=[]\n",
    "    uploads=[]\n",
    "    geos=[]\n",
    "    for photo in photos:\n",
    "        if count< MAX_COUNT:\n",
    "            count=count+1\n",
    "            print(\"Fetching url for image number {}\".format(count))\n",
    "            try:\n",
    "                url=photo.get('url_o')\n",
    "                urls.append(url)\n",
    "                upload=photo.get('date_upload')\n",
    "                uploads.append(upload)\n",
    "                geo=photo.get('geo')\n",
    "                geos.append(geo)\n",
    "            except:\n",
    "                print(\"Url for image number {} could not be fetched\".format(count))\n",
    "        else:\n",
    "            print(\"Done fetching urls, fetched {} urls out of {}\".format(len(urls),MAX_COUNT))\n",
    "            break\n",
    "    urls=pd.Series(urls)\n",
    "    uploads=pd.Series(uploads)\n",
    "    geos=pd.Series(geos)\n",
    "    print(\"Writing out the urls in the current directory\")\n",
    "    urls.to_csv(image_tag+\"_urls.csv\")\n",
    "    uploads.to_csv(image_tag+\"_uploads.csv\")\n",
    "    goes.to_csv(image_tag+\"_geos.csv\")\n",
    "    print(\"Done!!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching url for image number 1\n",
      "Fetching url for image number 2\n",
      "Fetching url for image number 3\n",
      "Fetching url for image number 4\n",
      "Fetching url for image number 5\n",
      "Fetching url for image number 6\n",
      "Fetching url for image number 7\n",
      "Fetching url for image number 8\n",
      "Fetching url for image number 9\n",
      "Fetching url for image number 10\n",
      "Fetching url for image number 11\n",
      "Fetching url for image number 12\n",
      "Fetching url for image number 13\n",
      "Fetching url for image number 14\n",
      "Fetching url for image number 15\n",
      "Fetching url for image number 16\n",
      "Fetching url for image number 17\n",
      "Fetching url for image number 18\n",
      "Fetching url for image number 19\n",
      "Fetching url for image number 20\n",
      "Fetching url for image number 21\n",
      "Fetching url for image number 22\n",
      "Fetching url for image number 23\n",
      "Fetching url for image number 24\n",
      "Fetching url for image number 25\n",
      "Fetching url for image number 26\n",
      "Fetching url for image number 27\n",
      "Fetching url for image number 28\n",
      "Fetching url for image number 29\n",
      "Fetching url for image number 30\n",
      "Fetching url for image number 31\n",
      "Fetching url for image number 32\n",
      "Fetching url for image number 33\n",
      "Fetching url for image number 34\n",
      "Fetching url for image number 35\n",
      "Fetching url for image number 36\n",
      "Fetching url for image number 37\n",
      "Fetching url for image number 38\n",
      "Fetching url for image number 39\n",
      "Fetching url for image number 40\n",
      "Fetching url for image number 41\n",
      "Fetching url for image number 42\n",
      "Fetching url for image number 43\n",
      "Fetching url for image number 44\n",
      "Fetching url for image number 45\n",
      "Fetching url for image number 46\n",
      "Fetching url for image number 47\n",
      "Fetching url for image number 48\n",
      "Fetching url for image number 49\n",
      "Fetching url for image number 50\n",
      "Fetching url for image number 51\n",
      "Fetching url for image number 52\n",
      "Fetching url for image number 53\n",
      "Fetching url for image number 54\n",
      "Fetching url for image number 55\n",
      "Fetching url for image number 56\n",
      "Fetching url for image number 57\n",
      "Fetching url for image number 58\n",
      "Fetching url for image number 59\n",
      "Fetching url for image number 60\n",
      "Fetching url for image number 61\n",
      "Fetching url for image number 62\n",
      "Fetching url for image number 63\n",
      "Fetching url for image number 64\n",
      "Fetching url for image number 65\n",
      "Fetching url for image number 66\n",
      "Fetching url for image number 67\n",
      "Fetching url for image number 68\n",
      "Fetching url for image number 69\n",
      "Fetching url for image number 70\n",
      "Fetching url for image number 71\n",
      "Fetching url for image number 72\n",
      "Fetching url for image number 73\n",
      "Fetching url for image number 74\n",
      "Fetching url for image number 75\n",
      "Fetching url for image number 76\n",
      "Fetching url for image number 77\n",
      "Fetching url for image number 78\n",
      "Fetching url for image number 79\n",
      "Fetching url for image number 80\n",
      "Fetching url for image number 81\n",
      "Fetching url for image number 82\n",
      "Fetching url for image number 83\n",
      "Fetching url for image number 84\n",
      "Fetching url for image number 85\n",
      "Fetching url for image number 86\n",
      "Fetching url for image number 87\n",
      "Fetching url for image number 88\n",
      "Fetching url for image number 89\n",
      "Fetching url for image number 90\n",
      "Fetching url for image number 91\n",
      "Fetching url for image number 92\n",
      "Fetching url for image number 93\n",
      "Fetching url for image number 94\n",
      "Fetching url for image number 95\n",
      "Fetching url for image number 96\n",
      "Fetching url for image number 97\n",
      "Fetching url for image number 98\n",
      "Fetching url for image number 99\n",
      "Fetching url for image number 100\n",
      "Done fetching urls, fetched 100 urls out of 100\n",
      "Writing out the urls in the current directory\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "get_urls(\"seabass\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only need the following code if running this from Terminal\n",
    "#def main(): \n",
    "#    tag=sys.argv[1]\n",
    "#    MAX_COUNT=int(sys.argv[2])\n",
    "#    get_urls(tag,MAX_COUNT)\n",
    "\n",
    "\n",
    "#if __name__=='__main__': \n",
    "#    main() \n",
    "# if running the module as the main program (e.g., in terminal: python getFishDat.py): execute function (main)\n",
    "# if module is imported by another program, _name_ is assigned to the module name \"getFishDat\": skip function (main)\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "def put_images(FILE_NAME):\n",
    "    urls=[]\n",
    "    with open(FILE_NAME,newline=\"\") as csvfile:\n",
    "        doc=csv.reader(csvfile,delimiter=\",\")\n",
    "        for row in doc:\n",
    "            if row[1].startswith(\"https\"):\n",
    "                urls.append(row[1])\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(),FILE_NAME.split(\"_\")[0])):\n",
    "        os.mkdir(FILE_NAME.split(\"_\")[0])\n",
    "    t0=time.time()\n",
    "    for url in enumerate(urls):\n",
    "        print(\"Starting download {} of \".format(url[0]+1),len(urls))\n",
    "        try:\n",
    "            resp=requests.get(url[1],stream=True)\n",
    "            path_to_write=os.path.join(os.getcwd(),FILE_NAME.split(\"_\")[0],url[1].split(\"/\")[-1])\n",
    "            outfile=open(path_to_write,'wb')\n",
    "            outfile.write(resp.content)\n",
    "            outfile.close()\n",
    "            print(\"Done downloading {} of {}\".format(url[0]+1,len(urls)))\n",
    "        except:\n",
    "            print(\"Failed to download url number {}\".format(url[0]))\n",
    "    t1=time.time()\n",
    "    print(\"Done with download, job took {} seconds\".format(t1-t0))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_images(\"seabass_urls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
