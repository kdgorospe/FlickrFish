{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flickrapi in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (2.4.0)\n",
      "Requirement already satisfied: requests>=2.2.1 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from flickrapi) (2.21.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from flickrapi) (1.12.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.3.1 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from flickrapi) (0.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.0 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from flickrapi) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from requests>=2.2.1->flickrapi) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from requests>=2.2.1->flickrapi) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from requests>=2.2.1->flickrapi) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from requests>=2.2.1->flickrapi) (2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/KGthatsme/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.4.0->flickrapi) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install flickrapi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flickrapi import FlickrAPI\n",
    "import pandas as pd\n",
    "import sys\n",
    "key='4d860f720718fdce373fe644da0d61b4'\n",
    "secret='813a60f10dffcbe6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(image_tag, MAX_COUNT):\n",
    "    \n",
    "\n",
    "    flickr = FlickrAPI(key, secret)\n",
    "    photos = flickr.walk(text=image_tag,\n",
    "                            tag_mode='all',\n",
    "                            tags=image_tag,\n",
    "                            has_geo=1,\n",
    "                            lat=41.604168,\n",
    "                            lon=-71.320683,\n",
    "                            extras='date_upload, date_taken, geo, url_o',\n",
    "                            per_page=50,\n",
    "                            sort='relevance'\n",
    "                        ) \n",
    "    count=0\n",
    "    urls=[]\n",
    "    uploads=[]\n",
    "    geos=[]\n",
    "    takens=[]\n",
    "    for photo in photos:\n",
    "        if count< MAX_COUNT:\n",
    "            count=count+1\n",
    "            print(\"Fetching url for image number {}\".format(count))\n",
    "            try:\n",
    "                url=photo.get('url_o')\n",
    "                urls.append(url)\n",
    "                upload=photo.get('date_upload')\n",
    "                uploads.append(upload)\n",
    "                taken=photo.get('date_taken')\n",
    "                takens.append(taken)\n",
    "                geo=photo.get('geo')\n",
    "                geos.append(geo)\n",
    "            except:\n",
    "                print(\"Url for image number {} could not be fetched\".format(count))\n",
    "        else:\n",
    "            print(\"Done fetching urls, fetched {} urls out of {}\".format(len(urls),MAX_COUNT))\n",
    "            break\n",
    "    urls=pd.Series(urls)\n",
    "    uploads=pd.Series(uploads)\n",
    "    geos=pd.Series(geos)\n",
    "    takens=pd.Series(takens)\n",
    "    print(\"Writing out the urls in the current directory\")\n",
    "    urls.to_csv(image_tag+\"_urls.csv\")\n",
    "    uploads.to_csv(image_tag+\"_uploads.csv\")\n",
    "    takens.to_csv(image_tag+\"_takens.csv\")\n",
    "    geos.to_csv(image_tag+\"_geos.csv\")\n",
    "    print(\"Done!!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching url for image number 1\n",
      "Fetching url for image number 2\n",
      "Fetching url for image number 3\n",
      "Fetching url for image number 4\n",
      "Fetching url for image number 5\n",
      "Fetching url for image number 6\n",
      "Writing out the urls in the current directory\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "get_urls(\"fishing\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only need the following code if running this from Terminal\n",
    "#def main(): \n",
    "#    tag=sys.argv[1]\n",
    "#    MAX_COUNT=int(sys.argv[2])\n",
    "#    get_urls(tag,MAX_COUNT)\n",
    "\n",
    "\n",
    "#if __name__=='__main__': \n",
    "#    main() \n",
    "# if running the module as the main program (e.g., in terminal: python getFishDat.py): execute function (main)\n",
    "# if module is imported by another program, _name_ is assigned to the module name \"getFishDat\": skip function (main)\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "def put_images(FILE_NAME):\n",
    "    urls=[]\n",
    "    with open(FILE_NAME,newline=\"\") as csvfile:\n",
    "        doc=csv.reader(csvfile,delimiter=\",\")\n",
    "        for row in doc:\n",
    "            if row[1].startswith(\"https\"):\n",
    "                urls.append(row[1])\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(),FILE_NAME.split(\"_\")[0])):\n",
    "        os.mkdir(FILE_NAME.split(\"_\")[0])\n",
    "    t0=time.time()\n",
    "    for url in enumerate(urls):\n",
    "        print(\"Starting download {} of \".format(url[0]+1),len(urls))\n",
    "        try:\n",
    "            resp=requests.get(url[1],stream=True)\n",
    "            path_to_write=os.path.join(os.getcwd(),FILE_NAME.split(\"_\")[0],url[1].split(\"/\")[-1])\n",
    "            outfile=open(path_to_write,'wb')\n",
    "            outfile.write(resp.content)\n",
    "            outfile.close()\n",
    "            print(\"Done downloading {} of {}\".format(url[0]+1,len(urls)))\n",
    "        except:\n",
    "            print(\"Failed to download url number {}\".format(url[0]))\n",
    "    t1=time.time()\n",
    "    print(\"Done with download, job took {} seconds\".format(t1-t0))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download 1 of  3\n",
      "Done downloading 1 of 3\n",
      "Starting download 2 of  3\n",
      "Done downloading 2 of 3\n",
      "Starting download 3 of  3\n",
      "Done downloading 3 of 3\n",
      "Done with download, job took 0.8717751502990723 seconds\n"
     ]
    }
   ],
   "source": [
    "put_images(\"fishing_urls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
