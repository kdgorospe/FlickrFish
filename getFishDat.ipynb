{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install flickrapi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flickrapi\n",
    "import pandas as pd\n",
    "#import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set \"key\" and \"secret\" in a local configuration file named flickr_APIkey.txt\n",
    "#for an example see: flickr_APIkey_example.txt\n",
    "#read-in key and secret from configuration file\n",
    "import os\n",
    "os.chdir(\"/Users/KGthatsme/Analyses/FlickrFish\")\n",
    "file=open(file=\"RESULTS/flickr_APIkey.txt\", mode=\"r\") #mode r = read the file\n",
    "key=file.readline()\n",
    "key=key.rstrip() # Remove all trailing whitespace (e.g., \\n)\n",
    "secret=file.readline()\n",
    "secret=secret.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of how to print json output of photo search\n",
    "image_tag=\"fish\"\n",
    "MAX_COUNT=5\n",
    "flickr = flickrapi.FlickrAPI(key, secret, format='parsed-json')\n",
    "fishes = flickr.photos.search(#text=image_tag, #use text parameter instead, which searches title, description, and tags\n",
    "                         #tag_mode='all',\n",
    "                         tags=image_tag, \n",
    "                         #bbox='-71.791037, 41.217233, -71.095148, 42.007849', # Narraganset Bay + RI Sound\n",
    "                         has_geo=1,\n",
    "                         #lat=41.604168,\n",
    "                         #lon=-71.320683,\n",
    "                         extras='url_o, date_upload, date_taken, geo, machine_tags', # still not sure what machine_tags is for\n",
    "                         per_page=MAX_COUNT,\n",
    "                         sort='relevance'\n",
    "                        )\n",
    "photos = fishes['photos']\n",
    "from pprint import pprint\n",
    "pprint(photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(image_tag, MAX_COUNT):    \n",
    "    flickr = flickrapi.FlickrAPI(key, secret)\n",
    "    count=0\n",
    "    urls=[]\n",
    "    uploads=[]\n",
    "    lats=[]\n",
    "    longs=[]\n",
    "    takens=[]\n",
    "    accuracies=[]\n",
    "    photos = flickr.walk(text=image_tag, #use text parameter instead, which searches title, description, and tags\n",
    "                         #tags=image_tag, \n",
    "                         bbox='-71.791037, 41.217233, -71.095148, 42.007849', # Narraganset Bay + RI Sound\n",
    "                         has_geo=1,\n",
    "                         #lat=41.604168,\n",
    "                         #lon=-71.320683,\n",
    "                         extras='url_t, date_upload, date_taken, geo',\n",
    "                         # use url_t instead of url_o; more search results provide access to \"thumbnail\" photo than the \"original\" photo\n",
    "                         per_page=MAX_COUNT, \n",
    "                         sort='relevance'\n",
    "                        )\n",
    "    for photo in photos:\n",
    "        if count<MAX_COUNT:\n",
    "            count=count+1\n",
    "            print(\"Fetching data for image number {}\".format(count))\n",
    "            try:\n",
    "                url=photo.get('url_t') \n",
    "                print(\"URL: {}\".format(url))\n",
    "                urls.append(url)\n",
    "                upload=photo.get('dateupload')\n",
    "                print(\"Upload: {}\".format(upload))\n",
    "                uploads.append(upload)\n",
    "                taken=photo.get('datetaken')\n",
    "                print(\"Taken: {}\".format(taken))\n",
    "                takens.append(taken)\n",
    "                lat=photo.get('latitude')\n",
    "                print(\"Latitude: {}\".format(lat))\n",
    "                lats.append(lat)\n",
    "                long=photo.get('longitude')\n",
    "                print(\"Longitude: {}\".format(lat))\n",
    "                longs.append(long)\n",
    "                accuracy=photo.get('accuracy')\n",
    "                print(\"Accuracy: {}\".format(accuracy)) # NOTE: may have to filter results by accuracy (16 = STREET LEVEL)\n",
    "                accuracies.append(accuracy)\n",
    "            except:\n",
    "                print(\"Url for image number {} could not be fetched\".format(count))\n",
    "        else:\n",
    "            print(\"Done fetching urls, fetched {} urls out of {}\".format(len(urls),MAX_COUNT))\n",
    "            break\n",
    "    urls=pd.Series(urls)\n",
    "    uploads=pd.Series(uploads)\n",
    "    lats=pd.Series(lats)\n",
    "    longs=pd.Series(longs)\n",
    "    takens=pd.Series(takens)\n",
    "    accuracies=pd.Series(accuracies)\n",
    "    print(\"Writing data to the current directory\")\n",
    "    urls.to_csv(image_tag+\"_urls.csv\")\n",
    "    uploads.to_csv(image_tag+\"_uploads.csv\")\n",
    "    takens.to_csv(image_tag+\"_takens.csv\")\n",
    "    lats.to_csv(image_tag+\"_lats.csv\")\n",
    "    longs.to_csv(image_tag+\"_longs.csv\")\n",
    "    accuracies.to_csv(image_tag+\"_accuracies.csv\")\n",
    "    print(\"Done!!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change wd to RESULTS folder\n",
    "os.chdir(\"/Users/KGthatsme/Analyses/FlickrFish/RESULTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tag='fish'\n",
    "MAX_COUNT=1000 # search results max out around 820\n",
    "get_urls(image_tag=image_tag, MAX_COUNT=MAX_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only need the following code if running this from Terminal\n",
    "#def main(): \n",
    "#    tag=sys.argv[1]\n",
    "#    MAX_COUNT=int(sys.argv[2])\n",
    "#    get_urls(tag,MAX_COUNT)\n",
    "\n",
    "\n",
    "#if __name__=='__main__': \n",
    "#    main() \n",
    "# if running the module as the main program (e.g., in terminal: python getFishDat.py): execute function (main)\n",
    "# if module is imported by another program, _name_ is assigned to the module name \"getFishDat\": skip function (main)\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "def put_images(image_tag):\n",
    "    urls=[]\n",
    "    FILE_NAME=image_tag+\"_urls.csv\"\n",
    "    with open(FILE_NAME,newline=\"\") as csvfile:\n",
    "        doc=csv.reader(csvfile,delimiter=\",\")\n",
    "        for row in doc:\n",
    "            if row[1].startswith(\"https\"):\n",
    "                urls.append(row[1])\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(),FILE_NAME.split(\"_\")[0])):\n",
    "        os.mkdir(FILE_NAME.split(\"_\")[0])\n",
    "    t0=time.time()\n",
    "    for url in enumerate(urls):\n",
    "        print(\"Starting download {} of \".format(url[0]+1),len(urls))\n",
    "        try:\n",
    "            resp=requests.get(url[1],stream=True)\n",
    "            path_to_write=os.path.join(os.getcwd(),FILE_NAME.split(\"_\")[0],url[1].split(\"/\")[-1])\n",
    "            outfile=open(path_to_write,'wb')\n",
    "            outfile.write(resp.content)\n",
    "            outfile.close()\n",
    "            print(\"Done downloading {} of {}\".format(url[0]+1,len(urls)))\n",
    "        except:\n",
    "            print(\"Failed to download url number {}\".format(url[0]))\n",
    "    t1=time.time()\n",
    "    print(\"Done with download, job took {} seconds\".format(t1-t0))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "put_images(image_tag=image_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE MAP OF QUERY LAT/LONG\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
