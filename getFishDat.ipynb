{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install flickrapi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flickrapi import FlickrAPI\n",
    "import pandas as pd\n",
    "#import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set \"key\" and \"secret\" in a local configuration file named flickr_APIkey.txt\n",
    "#for an example see: flickr_APIkey_example.txt\n",
    "#read-in key and secret from configuration file\n",
    "import os\n",
    "os.chdir(\"/Users/KGthatsme/Analyses/FlickrFish\")\n",
    "file=open(file=\"flickr_APIkey.txt\", mode=\"r\") #mode r = read the file\n",
    "key=file.readline()\n",
    "key=key.rstrip() # Remove all trailing whitespace (e.g., \\n)\n",
    "secret=file.readline()\n",
    "secret=secret.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(image_tag, MAX_COUNT):    \n",
    "    flickr = FlickrAPI(key, secret)\n",
    "    count=0\n",
    "    urls=[]\n",
    "    uploads=[]\n",
    "    geos=[]\n",
    "    takens=[]\n",
    "    for photo in flickr.walk(#text=image_tag, # Temporarily remove image_tag parameter, to see if I can get any geo information\n",
    "                         #tag_mode='all',\n",
    "                         #tags=image_tag, #use text parameter instead, which searches title, description, and tags\n",
    "                         #bbox='-71.791037, 41.217233, -71.095148, 42.007849', # Narraganset Bay + RI Sound\n",
    "                         has_geo=1,\n",
    "                         #lat=41.604168,\n",
    "                         #lon=-71.320683,\n",
    "                         extras='url_o, date_upload, date_taken, geo',\n",
    "                         per_page=MAX_COUNT,\n",
    "                         sort='relevance'\n",
    "                        ):\n",
    "        if count< MAX_COUNT:\n",
    "            count=count+1\n",
    "            print(\"Fetching data for image number {}\".format(count))\n",
    "            try:\n",
    "                url=photo.get('url_o')\n",
    "                print(\"URL: {}\".format(url))\n",
    "                urls.append(url)\n",
    "                upload=photo.get('date_upload')\n",
    "                print(\"Upload: {}\".format(upload))\n",
    "                uploads.append(upload)\n",
    "                taken=photo.get('date_taken')\n",
    "                print(\"Taken: {}\".format(taken))\n",
    "                takens.append(taken)\n",
    "                geo=photo.get('geo')\n",
    "                print(\"Geo: {}\".format(geo))\n",
    "                geos.append(geo)\n",
    "            except:\n",
    "                print(\"Url for image number {} could not be fetched\".format(count))\n",
    "        else:\n",
    "            print(\"Done fetching urls, fetched {} urls out of {}\".format(len(urls),MAX_COUNT))\n",
    "            break\n",
    "    urls=pd.Series(urls)\n",
    "    uploads=pd.Series(uploads)\n",
    "    geos=pd.Series(geos)\n",
    "    takens=pd.Series(takens)\n",
    "    print(\"Writing out the urls in the current directory\")\n",
    "    urls.to_csv(image_tag+\"_urls.csv\")\n",
    "    uploads.to_csv(image_tag+\"_uploads.csv\")\n",
    "    takens.to_csv(image_tag+\"_takens.csv\")\n",
    "    geos.to_csv(image_tag+\"_geos.csv\")\n",
    "    print(\"Done!!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change wd to RESULTS folder\n",
    "os.chdir(\"/Users/KGthatsme/Analyses/FlickrFish/RESULTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tag=\"fish\"\n",
    "MAX_COUNT=100\n",
    "get_urls(image_tag=image_tag, MAX_COUNT=MAX_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only need the following code if running this from Terminal\n",
    "#def main(): \n",
    "#    tag=sys.argv[1]\n",
    "#    MAX_COUNT=int(sys.argv[2])\n",
    "#    get_urls(tag,MAX_COUNT)\n",
    "\n",
    "\n",
    "#if __name__=='__main__': \n",
    "#    main() \n",
    "# if running the module as the main program (e.g., in terminal: python getFishDat.py): execute function (main)\n",
    "# if module is imported by another program, _name_ is assigned to the module name \"getFishDat\": skip function (main)\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "def put_images(image_tag):\n",
    "    urls=[]\n",
    "    FILE_NAME=image_tag+\"_urls.csv\"\n",
    "    with open(FILE_NAME,newline=\"\") as csvfile:\n",
    "        doc=csv.reader(csvfile,delimiter=\",\")\n",
    "        for row in doc:\n",
    "            if row[1].startswith(\"https\"):\n",
    "                urls.append(row[1])\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(),FILE_NAME.split(\"_\")[0])):\n",
    "        os.mkdir(FILE_NAME.split(\"_\")[0])\n",
    "    t0=time.time()\n",
    "    for url in enumerate(urls):\n",
    "        print(\"Starting download {} of \".format(url[0]+1),len(urls))\n",
    "        try:\n",
    "            resp=requests.get(url[1],stream=True)\n",
    "            path_to_write=os.path.join(os.getcwd(),FILE_NAME.split(\"_\")[0],url[1].split(\"/\")[-1])\n",
    "            outfile=open(path_to_write,'wb')\n",
    "            outfile.write(resp.content)\n",
    "            outfile.close()\n",
    "            print(\"Done downloading {} of {}\".format(url[0]+1,len(urls)))\n",
    "        except:\n",
    "            print(\"Failed to download url number {}\".format(url[0]))\n",
    "    t1=time.time()\n",
    "    print(\"Done with download, job took {} seconds\".format(t1-t0))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "put_images(image_tag=image_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
